#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stable Diffusion WebUI æ¨¡å‹ä¸‹è½½å™¨
æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤šæ¬¡é‡è¯•
"""

import os
import sys
import requests
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelDownloader:
    def __init__(self, base_dir: str = ".", download_dir: str = "D:/download"):
        self.base_dir = Path(base_dir)
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.models = {
            # å¿…éœ€æ¨¡å‹
            "sd_1_5": {
                "name": "Stable Diffusion 1.5",
                "url": "https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors",
                "target": "models/Stable-diffusion/v1-5-pruned-emaonly.safetensors",
                "size": "3.97GB",
                "priority": 1,
                "required": True
            },
            
            # æ¨èæ¨¡å‹
            "vae_mse": {
                "name": "VAE MSE",
                "url": "https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors",
                "target": "models/VAE/vae-ft-mse-840000-ema-pruned.safetensors",
                "size": "335MB",
                "priority": 2,
                "required": False
            },
            
            "realesrgan": {
                "name": "RealESRGAN 4x",
                "url": "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth",
                "target": "models/ESRGAN/RealESRGAN_x4plus.pth",
                "size": "67MB",
                "priority": 3,
                "required": False
            },
            
            "gfpgan": {
                "name": "GFPGAN v1.4",
                "url": "https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth",
                "target": "models/GFPGAN/GFPGANv1.4.pth",
                "size": "348MB",
                "priority": 4,
                "required": False
            }
        }
    
    def download_with_resume(self, url: str, target_path: Path, max_retries: int = 10) -> bool:
        """æ”¯æŒæ–­ç‚¹ç»­ä¼ çš„ä¸‹è½½å‡½æ•°"""
        target_path.parent.mkdir(parents=True, exist_ok=True)
        temp_path = self.download_dir / f"{target_path.name}.tmp"
        
        # æ£€æŸ¥å·²ä¸‹è½½çš„å¤§å°
        resume_pos = 0
        if temp_path.exists():
            resume_pos = temp_path.stat().st_size
            logger.info(f"å‘ç°ä¸´æ—¶æ–‡ä»¶ï¼Œä» {resume_pos} å­—èŠ‚å¤„ç»§ç»­ä¸‹è½½")
        
        headers = {}
        if resume_pos > 0:
            headers['Range'] = f'bytes={resume_pos}-'
        
        for attempt in range(max_retries):
            try:
                logger.info(f"å¼€å§‹ä¸‹è½½ {url} (å°è¯• {attempt + 1}/{max_retries})")
                
                response = requests.get(url, headers=headers, stream=True, timeout=30)
                
                # æ£€æŸ¥æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                if resume_pos > 0 and response.status_code not in [206, 200]:
                    logger.warning("æœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œé‡æ–°å¼€å§‹ä¸‹è½½")
                    resume_pos = 0
                    headers = {}
                    temp_path.unlink(missing_ok=True)
                    continue
                
                response.raise_for_status()
                
                # è·å–æ–‡ä»¶æ€»å¤§å°
                if 'content-length' in response.headers:
                    total_size = int(response.headers['content-length'])
                    if resume_pos > 0:
                        total_size += resume_pos
                else:
                    total_size = None
                
                # ä¸‹è½½æ–‡ä»¶
                mode = 'ab' if resume_pos > 0 else 'wb'
                downloaded = resume_pos
                
                with open(temp_path, mode) as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            # æ˜¾ç¤ºè¿›åº¦
                            if total_size:
                                progress = (downloaded / total_size) * 100
                                print(f"\rä¸‹è½½è¿›åº¦: {downloaded:,} / {total_size:,} å­—èŠ‚ ({progress:.1f}%)", end='')
                            else:
                                print(f"\rå·²ä¸‹è½½: {downloaded:,} å­—èŠ‚", end='')
                
                print()  # æ¢è¡Œ
                
                # ä¸‹è½½å®Œæˆï¼Œç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
                target_path.parent.mkdir(parents=True, exist_ok=True)
                temp_path.rename(target_path)
                logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {target_path}")
                return True
                
            except requests.exceptions.RequestException as e:
                logger.error(f"ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    logger.info("3ç§’åé‡è¯•...")
                    import time
                    time.sleep(3)
                else:
                    logger.error(f"âŒ ä¸‹è½½å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {url}")
                    return False
            except Exception as e:
                logger.error(f"ä¸‹è½½å¼‚å¸¸: {e}")
                return False
        
        return False
    
    def check_model_exists(self, model_key: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨"""
        model = self.models[model_key]
        target_path = self.base_dir / model["target"]
        return target_path.exists()
    
    def download_model(self, model_key: str) -> bool:
        """ä¸‹è½½å•ä¸ªæ¨¡å‹"""
        if model_key not in self.models:
            logger.error(f"æœªçŸ¥æ¨¡å‹: {model_key}")
            return False
        
        model = self.models[model_key]
        target_path = self.base_dir / model["target"]
        
        if self.check_model_exists(model_key):
            logger.info(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model['name']}")
            return True
        
        logger.info(f"ğŸ“¦ å¼€å§‹ä¸‹è½½: {model['name']} ({model['size']})")
        logger.info(f"ğŸ“ ç›®æ ‡ä½ç½®: {target_path}")
        
        return self.download_with_resume(model["url"], target_path)
    
    def download_required_models(self) -> bool:
        """ä¸‹è½½æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½å¿…éœ€æ¨¡å‹...")
        
        required_models = [k for k, v in self.models.items() if v["required"]]
        required_models.sort(key=lambda k: self.models[k]["priority"])
        
        success_count = 0
        for model_key in required_models:
            if self.download_model(model_key):
                success_count += 1
            else:
                logger.error(f"âŒ å¿…éœ€æ¨¡å‹ä¸‹è½½å¤±è´¥: {self.models[model_key]['name']}")
                return False
        
        logger.info(f"ğŸ‰ å¿…éœ€æ¨¡å‹ä¸‹è½½å®Œæˆ: {success_count}/{len(required_models)}")
        return True
    
    def download_all_models(self) -> bool:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰æ¨¡å‹...")
        
        all_models = list(self.models.keys())
        all_models.sort(key=lambda k: self.models[k]["priority"])
        
        success_count = 0
        for model_key in all_models:
            if self.download_model(model_key):
                success_count += 1
        
        logger.info(f"ğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆ: {success_count}/{len(all_models)}")
        return success_count == len(all_models)
    
    def show_status(self):
        """æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€"""
        logger.info("ğŸ“Š æ¨¡å‹çŠ¶æ€:")
        
        for model_key, model in self.models.items():
            status = "âœ… å·²å®‰è£…" if self.check_model_exists(model_key) else "âŒ æœªå®‰è£…"
            required = "å¿…éœ€" if model["required"] else "å¯é€‰"
            logger.info(f"  {model['name']}: {status} ({required}, {model['size']})")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Stable Diffusion WebUI æ¨¡å‹ä¸‹è½½å™¨")
    parser.add_argument("--all", action="store_true", help="ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--required", action="store_true", help="åªä¸‹è½½å¿…éœ€æ¨¡å‹")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€")
    parser.add_argument("--model", type=str, help="ä¸‹è½½æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--base-dir", type=str, default=".", help="WebUIåŸºç¡€ç›®å½•")
    parser.add_argument("--download-dir", type=str, default="D:/download", help="ä¸´æ—¶ä¸‹è½½ç›®å½•")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.base_dir, args.download_dir)
    
    if args.status:
        downloader.show_status()
    elif args.all:
        downloader.download_all_models()
    elif args.required:
        downloader.download_required_models()
    elif args.model:
        downloader.download_model(args.model)
    else:
        logger.info("ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
        downloader.show_status()

if __name__ == "__main__":
    main()
