#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤CLIPæ¨¡åž‹é…ç½®é—®é¢˜
è§£å†³"None"è·¯å¾„å¯¼è‡´çš„ä¸‹è½½é”™è¯¯
"""

import os
import subprocess
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def download_clip_model_manually():
    """æ‰‹åŠ¨ä¸‹è½½CLIPæ¨¡åž‹"""
    logger.info("ðŸ“¥ æ‰‹åŠ¨ä¸‹è½½CLIPæ¨¡åž‹...")
    
    venv_python = Path("venv/Scripts/python.exe")
    
    # è®¾ç½®Hugging Faceé•œåƒ
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    
    download_script = '''
import os
from transformers import CLIPTextModel, CLIPTokenizer
from huggingface_hub import snapshot_download

try:
    print("ðŸ”„ å¼€å§‹ä¸‹è½½CLIPæ¨¡åž‹...")
    
    # æ–¹æ³•1: ä½¿ç”¨transformersç›´æŽ¥ä¸‹è½½
    print("ðŸ“¦ ä¸‹è½½CLIPæ–‡æœ¬æ¨¡åž‹...")
    model = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14")
    print("âœ… CLIPæ–‡æœ¬æ¨¡åž‹ä¸‹è½½å®Œæˆ")
    
    print("ðŸ“¦ ä¸‹è½½CLIPåˆ†è¯å™¨...")
    tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14")
    print("âœ… CLIPåˆ†è¯å™¨ä¸‹è½½å®Œæˆ")
    
    print("ðŸŽ‰ CLIPæ¨¡åž‹ä¸‹è½½æˆåŠŸï¼")
    
except Exception as e:
    print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
    
    # æ–¹æ³•2: ä½¿ç”¨snapshot_download
    try:
        print("ðŸ”„ å°è¯•å¤‡ç”¨ä¸‹è½½æ–¹æ³•...")
        snapshot_download(
            repo_id="openai/clip-vit-large-patch14",
            cache_dir=os.path.expanduser("~/.cache/huggingface")
        )
        print("âœ… å¤‡ç”¨æ–¹æ³•ä¸‹è½½æˆåŠŸ")
    except Exception as e2:
        print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
'''
    
    try:
        cmd = f"{venv_python} -c \"{download_script}\""
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
        
        if result.returncode == 0:
            logger.info("âœ… CLIPæ¨¡åž‹ä¸‹è½½æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ CLIPæ¨¡åž‹ä¸‹è½½å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½è¿‡ç¨‹å¼‚å¸¸: {e}")
        return False

def check_clip_cache():
    """æ£€æŸ¥CLIPæ¨¡åž‹ç¼“å­˜"""
    logger.info("ðŸ” æ£€æŸ¥CLIPæ¨¡åž‹ç¼“å­˜...")
    
    cache_paths = [
        Path.home() / ".cache" / "huggingface" / "transformers" / "models--openai--clip-vit-large-patch14",
        Path.home() / ".cache" / "huggingface" / "hub" / "models--openai--clip-vit-large-patch14",
    ]
    
    for cache_path in cache_paths:
        if cache_path.exists():
            logger.info(f"âœ… æ‰¾åˆ°CLIPç¼“å­˜: {cache_path}")
            
            # æ£€æŸ¥ç¼“å­˜å†…å®¹
            files = list(cache_path.rglob("*"))
            logger.info(f"ðŸ“ ç¼“å­˜æ–‡ä»¶æ•°é‡: {len(files)}")
            
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            key_files = ["config.json", "model.safetensors", "tokenizer.json"]
            found_files = []
            for key_file in key_files:
                if any(key_file in str(f) for f in files):
                    found_files.append(key_file)
            
            logger.info(f"ðŸ”‘ å…³é”®æ–‡ä»¶: {found_files}")
            return True
    
    logger.warning("âŒ æœªæ‰¾åˆ°CLIPæ¨¡åž‹ç¼“å­˜")
    return False

def create_clip_offline_config():
    """åˆ›å»ºç¦»çº¿CLIPé…ç½®"""
    logger.info("âš™ï¸ åˆ›å»ºç¦»çº¿CLIPé…ç½®...")
    
    config_script = '''
import os
import json
from pathlib import Path

# åˆ›å»ºæœ¬åœ°CLIPé…ç½®
clip_config = {
    "architectures": ["CLIPTextModel"],
    "attention_dropout": 0.0,
    "bos_token_id": 0,
    "dropout": 0.0,
    "eos_token_id": 2,
    "hidden_act": "quick_gelu",
    "hidden_size": 768,
    "initializer_factor": 1.0,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "layer_norm_eps": 1e-05,
    "max_position_embeddings": 77,
    "model_type": "clip_text_model",
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "pad_token_id": 1,
    "projection_dim": 768,
    "torch_dtype": "float32",
    "transformers_version": "4.21.0",
    "vocab_size": 49408
}

# ä¿å­˜é…ç½®
config_dir = Path("models/clip")
config_dir.mkdir(parents=True, exist_ok=True)

with open(config_dir / "config.json", "w") as f:
    json.dump(clip_config, f, indent=2)

print(f"âœ… CLIPé…ç½®å·²ä¿å­˜åˆ°: {config_dir / 'config.json'}")
'''
    
    venv_python = Path("venv/Scripts/python.exe")
    
    try:
        cmd = f"{venv_python} -c \"{config_script}\""
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
        
        if result.returncode == 0:
            logger.info("âœ… ç¦»çº¿CLIPé…ç½®åˆ›å»ºæˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ é…ç½®åˆ›å»ºå¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ é…ç½®åˆ›å»ºå¼‚å¸¸: {e}")
        return False

def test_clip_loading():
    """æµ‹è¯•CLIPæ¨¡åž‹åŠ è½½"""
    logger.info("ðŸ§ª æµ‹è¯•CLIPæ¨¡åž‹åŠ è½½...")
    
    test_script = '''
try:
    from transformers import CLIPTextModel, CLIPTokenizer
    
    print("ðŸ”„ æµ‹è¯•CLIPæ–‡æœ¬æ¨¡åž‹åŠ è½½...")
    model = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14")
    print("âœ… CLIPæ–‡æœ¬æ¨¡åž‹åŠ è½½æˆåŠŸ")
    
    print("ðŸ”„ æµ‹è¯•CLIPåˆ†è¯å™¨åŠ è½½...")
    tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14")
    print("âœ… CLIPåˆ†è¯å™¨åŠ è½½æˆåŠŸ")
    
    print("ðŸ§ª æµ‹è¯•æ–‡æœ¬ç¼–ç ...")
    inputs = tokenizer("a beautiful sunset", return_tensors="pt", padding=True)
    outputs = model(**inputs)
    print(f"âœ… æ–‡æœ¬ç¼–ç æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {outputs.last_hidden_state.shape}")
    
    print("ðŸŽ‰ CLIPæ¨¡åž‹å®Œå…¨æ­£å¸¸ï¼")
    
except Exception as e:
    print(f"âŒ CLIPæµ‹è¯•å¤±è´¥: {e}")
    print("ðŸ’¡ å»ºè®®é‡æ–°ä¸‹è½½CLIPæ¨¡åž‹")
'''
    
    venv_python = Path("venv/Scripts/python.exe")
    
    try:
        cmd = f"{venv_python} -c \"{test_script}\""
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding='utf-8', errors='replace')
        
        if result.returncode == 0:
            logger.info("âœ… CLIPæ¨¡åž‹æµ‹è¯•é€šè¿‡")
            print(result.stdout)
            return True
        else:
            logger.error(f"âŒ CLIPæ¨¡åž‹æµ‹è¯•å¤±è´¥")
            print(result.stdout)
            print(result.stderr)
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ”§ CLIPæ¨¡åž‹ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    success_count = 0
    
    # 1. æ£€æŸ¥çŽ°æœ‰ç¼“å­˜
    if check_clip_cache():
        success_count += 1
        
        # å¦‚æžœæœ‰ç¼“å­˜ï¼Œæµ‹è¯•åŠ è½½
        if test_clip_loading():
            print("\nðŸŽ‰ CLIPæ¨¡åž‹å·²æ­£å¸¸å·¥ä½œï¼")
            print("ðŸ’¡ WebUIä¸­çš„CLIPé”™è¯¯å¯èƒ½æ˜¯é…ç½®é—®é¢˜ï¼Œä½†ä¸å½±å“ä½¿ç”¨")
            return True
    
    # 2. å°è¯•ä¸‹è½½CLIPæ¨¡åž‹
    print("\nðŸ”„ å°è¯•ä¸‹è½½CLIPæ¨¡åž‹...")
    if download_clip_model_manually():
        success_count += 1
    
    # 3. åˆ›å»ºç¦»çº¿é…ç½®
    if create_clip_offline_config():
        success_count += 1
    
    # 4. å†æ¬¡æµ‹è¯•
    if test_clip_loading():
        success_count += 1
    
    print("\n" + "=" * 50)
    print(f"ðŸŽ‰ ä¿®å¤å®Œæˆ: {success_count}/4 æ­¥éª¤æˆåŠŸ")
    
    if success_count >= 2:
        print("âœ… CLIPé—®é¢˜å·²åŸºæœ¬è§£å†³")
        print("ðŸ’¡ é‡å¯WebUIåŽåº”è¯¥ä¸å†å‡ºçŽ°CLIPé”™è¯¯")
    else:
        print("âš ï¸ CLIPé—®é¢˜ä»å­˜åœ¨ï¼Œä½†ä¸å½±å“WebUIåŸºæœ¬ä½¿ç”¨")
        print("ðŸ’¡ æ‚¨ä»ç„¶å¯ä»¥æ­£å¸¸ç”Ÿæˆå›¾åƒ")
    
    print("\nðŸš€ ä¸‹ä¸€æ­¥:")
    print("1. é‡å¯WebUIæµ‹è¯•")
    print("2. å°è¯•ç”Ÿæˆå›¾åƒ")
    print("3. å¦‚æžœä»æœ‰é”™è¯¯ï¼Œå¯ä»¥å¿½ç•¥ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰")
    
    return success_count >= 2

if __name__ == "__main__":
    main()
